{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SL-GPS: Supervised Learning - Global Pathway Selection","text":"<p>[cite_start]This repository contains the means to create a neural network architecture for dynamic chemistry reduction based on reduction results from Global Pathway Selection (GPS)[cite: 186554, 186638].</p> <p>The basic procedure is: 1. [cite_start]Run adaptive GPS for 0D auto-ignition simulation to create a dataset[cite: 186554, 186638]. 2. [cite_start]Use this dataset for training the Artificial Neural Network (ANN)[cite: 186554, 186638].</p>"},{"location":"#contact","title":"Contact","text":"<p>For questions, discussions, code issues, or pull requests, please contact: * [cite_start]Rohit Mishra (rmishra@tamu.edu) [cite: 186554] * [cite_start]Aaron Nelson (aaronnelson@tamu.edu) [cite: 186554]</p> <p>[cite_start]You can also join the Discord channel: Discord Channel[cite: 186554].</p>"},{"location":"#how-to-cite","title":"How to Cite","text":"<p>If you use this work, please cite the following publication: - [cite_start]Mishra, R., Nelson, A., Jarrahbashi, D., \"Adaptive global pathway selection using artificial neural networks: A-priori study\", Combustion and Flame, 244 (2022) 112279[cite: 186554, 186638].   * [cite_start]Link to Publication [cite: 186554, 186638]</p> <p>Code developed entirely in Python 3. [cite_start]Dependent packages include Cantera 2, Tensorflow 2, pandas, sklearn, numpy, pickle, and networkx. [cite: 186554, 186638]</p>"},{"location":"code_structure/","title":"Code Structure and Customization","text":"<p>The core functionality of SL-GPS is modular, allowing key components to be customized.</p>"},{"location":"code_structure/#key-files-for-customization","title":"Key Files for Customization","text":"File Description Customization Notes <code>main.py</code> Main script for generating training data and triggering model training. [cite_start]Adjust input parameters like <code>t_rng</code>, <code>p_rng</code>, <code>n_cases</code>, <code>alpha</code>, and <code>species_ranges</code> to control the data generation process[cite: 186550]. <code>mech_train.py</code> Contains the logic for the Neural Network training. The architecture of the neural network can be modified in the indicated section of code. The default is typically one hidden layer with 16 neurons. [cite_start]Other hyperparameters (e.g., stopping criteria) can also be edited[cite: 186550]. <code>SL_GPS.py</code> Main script for running the adaptive reduction simulation. [cite_start]Adjust simulation controls like initial conditions, <code>t_end</code>, and the mechanism update frequency (<code>norm_Dt</code>, <code>ign_Dt</code>)[cite: 186550, 186638]. <code>tests/converth5ToPb.ipynb</code> Jupyter notebook example. [cite_start]Used to convert the trained <code>.h5</code> model to a <code>.pb</code> (frozen graph) format for use in other platforms like OpenFOAM[cite: 186554]."},{"location":"code_structure/#default-ann-architecture","title":"Default ANN Architecture","text":"<p>[cite_start]The default neural network architecture is specified in <code>mech_train.py</code>[cite: 186554].</p> <ul> <li>[cite_start]Default Layers: It usually defaults to a single hidden layer with 16 neurons[cite: 186550].</li> <li>[cite_start]Activation: Sigmoid activation function is used[cite: 186550].</li> <li>[cite_start]Loss Function: Binary crossentropy loss is used[cite: 186550].</li> </ul> <p>[cite_start]Note: One version of the repository notes a default of \"16x8 (2 hidden layers)\" in its README, suggesting the architecture may be subject to changes and should be verified in the source code if an older version is in use. [cite: 186554]</p>"},{"location":"setup/","title":"Setup &amp; Installation","text":"<p>[cite_start]The code was developed entirely in Python 3[cite: 186554, 186638].</p>"},{"location":"setup/#requirements","title":"Requirements","text":"<p>[cite_start]The primary dependencies are[cite: 186550]: - Cantera (<code>cantera==2.6.0</code>) - Tensorflow - Matplotlib - NumPy (<code>numpy==1.26.4</code>) - Scikit-learn - NetworkX - SL-GPS Library (<code>git+https://github.com/ctftamu/SL-GPS.git</code>)</p>"},{"location":"setup/#installation-steps","title":"Installation Steps","text":"<ol> <li> <p>Install base libraries: <code>bash     pip install matplotlib tensorflow</code></p> </li> <li> <p>Install specific Python dependencies: <code>bash     pip install \"numpy==1.26.4\" networkx scikit-learn</code></p> </li> <li> <p>Install Cantera: (Ensure the correct version)     <code>bash     pip install --no-cache-dir \"cantera==2.6.0\"</code></p> </li> <li> <p>Install the SL-GPS core library: <code>bash     pip install \"git+[https://github.com/ctftamu/SL-GPS.git](https://github.com/ctftamu/SL-GPS.git)\"</code>     [cite_start]Alternatively, if the package is published, a simple <code>pip install slgps</code> would suffice. [cite: 186638]</p> </li> <li> <p>[cite_start]Verify installation: Test your installation by running any of the files in the <code>tests/</code> folder[cite: 186554, 186638].</p> </li> </ol>"},{"location":"workflow/","title":"Usage Workflow","text":"<p>[cite_start]The repository facilitates a two-stage workflow: Creating an ANN (Training) and Testing the ANN (Simulation)[cite: 186550, 186638].</p>"},{"location":"workflow/#1-creating-an-ann-training","title":"1. Creating an ANN (Training)","text":"<p>To produce a new ANN as an <code>.h5</code> file, run the <code>main.py</code> file.</p>"},{"location":"workflow/#data-generation","title":"Data Generation","text":"<p>[cite_start]If the input parameter <code>'data_path'</code> specified in <code>main.py</code> does not point to a pre-existing directory containing state vector and reduced species data, the script will perform the following[cite: 186550]: 1.  [cite_start]Run a series of autoignition simulations across a random set of initial conditions (T, P, $\\phi$)[cite: 186550]. 2.  [cite_start]Run classic GPS on the simulation results to produce the training dataset[cite: 186550]. 3.  [cite_start]The simulation parameters are controlled by variables in <code>main.py</code>, including the <code>fuel</code>, <code>detailed mechanism</code> (<code>mech_file</code>), ranges of initial temperature (<code>t_rng</code>), pressure (<code>p_rng</code>), and equivalence ratio (<code>phi_rng</code>), the <code>number of cases</code> (<code>n_cases</code>), and the tolerance of GPS in including species (<code>alpha</code>)[cite: 186550].</p>"},{"location":"workflow/#ann-training","title":"ANN Training","text":"<p>[cite_start]Once data exists at the specified directory, an ANN will be trained[cite: 186550].</p> <ul> <li>[cite_start]The trained ANN is stored as an .h5 file in a directory specified in <code>main.py</code> (variable: <code>model_path</code>)[cite: 186550].</li> <li>The ANN predicts the inclusion of a subset of species (variable species). The full species list is partitioned into three groups based on training data frequency thresholds (<code>always_threshold</code>, <code>never_threshold</code>):<ul> <li>Variable Species (determined by ANN)</li> <li>[cite_start]Always Included species (<code>always_spec_nums.csv</code>) [cite: 186550]</li> <li>[cite_start]Never Included species (<code>never_spec_nums.csv</code>) [cite: 186550]</li> </ul> </li> </ul>"},{"location":"workflow/#2-testing-the-ann-simulation","title":"2. Testing the ANN (Simulation)","text":"<p>[cite_start]To test a trained ANN by adaptively reducing a mechanism using the SL-GPS method over the course of an autoignition simulation, run <code>SL_GPS.py</code>[cite: 186550].</p> <p>[cite_start]Parameters within <code>SL_GPS.py</code> control the following[cite: 186550, 186638]: * Initial conditions (<code>T0_in</code>, <code>phi</code>, <code>atm</code>) * Simulation duration (<code>t_end</code>) * Frequency of mechanism updates (<code>norm_Dt</code>, <code>ign_Dt</code>) * Paths to the trained ANN and scaler (<code>model_path</code>, <code>scaler_path</code>)</p> <p>[cite_start]The result of this simulation, including temperature, heat release rate, mole fractions, and net reaction rates, is stored in a .pkl file[cite: 186550, 186638].</p>"},{"location":"workflow/#3-plotting-results","title":"3. Plotting Results","text":"<p>To visualize the simulation results, run <code>display_sim_data.py</code> with the path to the <code>.pkl</code> file in the input parameters. [cite_start]It uses matplotlib to display time profiles of[cite: 186550, 186638]: * Temperature * Heat release rate * Mole fractions for selected species * The number of species and reactions in the reduced mechanisms selected by the ANN over time</p>"}]}