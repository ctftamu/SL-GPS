#!/bin/bash
##ENVIRONMENT SETTINGS; CHANGE WITH CAUTION
##SBATCH --export=ALL                #Do not propagate environment
#SBATCH --get-user-env=L             #Replicate login environment

##NECESSARY JOB SPECIFICATIONS
#SBATCH --job-name=GPS_data #Set the job name to "JobExample3"
#SBATCH --time=10:00:00            #Set the wall clock limit to 1 Day and 12hr
#SBATCH --ntasks=28  #128                 #Request 128 tasks
#SBATCH --ntasks-per-node=28 #8        #Request 2 tasks/cores per node 
#SBATCH --mem=50G                 #Request 4096MB (4GB) per node / maximum = 56G 
#SBATCH --output=log.%j      #Send stdout/err to "Example3Out.[jobID]"

##OPTIONAL JOB SPECIFICATIONS
#SBATCH --account=122820192558        #Set billing account to 123456


#First Executable Line
#ml Python/3.7.4-GCCcore-8.3.0
#virtualenv --system-site-packages venv
#source venv/bin/activate
#pip install numpy

#ml Anaconda2/2019.10
#conda create --name myenv python=3.7.4
#conda activate myenv
#conda install numpy


#module load WebProxy
#ml Python/3.10.4-GCCcore-11.3.0
#virtualenv --system-site-packages venv
#source venv/bin/activate
#pip install --upgrade pip
#pip install numpy pandas cantera networkx tensorflow scikit-learn

ml Python/3.10.4-GCCcore-11.3.0
source /scratch/helpdesk/rmishra/venv/bin/activate

python sup_plot.py > log_plot

#python train_data_2D_parallel.py > log
